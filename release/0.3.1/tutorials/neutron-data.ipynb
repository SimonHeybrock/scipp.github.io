{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutron Data\n",
    "\n",
    "This is the continuation from [Multi-dimensional datasets](https://scipp.github.io/tutorials/multi-d-datasets.html) tutorial.\n",
    "Note that this notebooks requires [Mantid](https://www.mantidproject.org/Main_Page) and data files that are, e.g., contained in the [Docker](https://hub.docker.com/r/scipp/scipp-jupyter-demo) image of scipp.\n",
    "Therefore, outputs are unfortunately not available on the published documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipp as sc\n",
    "from scipp.plot import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Nexus files\n",
    "\n",
    "Scipp does not support native loading of [Nexus](https://www.nexusformat.org/) files at this point.\n",
    "However, it can leverage Mantid to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = sc.Dataset()\n",
    "# Load only a single bank to reduce memory consumption, so this runs on a laptop\n",
    "events['sample'] = sc.neutron.load(\n",
    "    filename='PG3_4844_event.nxs',\n",
    "    load_pulse_times=True,\n",
    "    mantid_args={'BankName': 'bank184',\n",
    "                 'LoadMonitors': True}) # Mantid does not load monitors by default\n",
    "events['vanadium'] = sc.neutron.load(\n",
    "    filename='PG3_4866_event.nxs',\n",
    "    load_pulse_times=False,\n",
    "    mantid_args={'BankName': 'bank184',\n",
    "                 'LoadMonitors': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that internally this calls `Load` or `LoadEventNexus` provided by Mantid.\n",
    "Scipp then converts from Mantid's `EventWorkspace` and `Workspace2D` to `DataArray`.\n",
    "Currently not all information from the Mantid workspaces is preserved in the data array.\n",
    "\n",
    "## Understanding the contents of the created dataset\n",
    "\n",
    "The dataset with loaded sample and vanadium data looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give a short discussion of each of the entries to familiarize ourselves with how data from a Mantid workspace is mapped onto a data array or dataset.\n",
    "\n",
    "### Dimensions and coordinates\n",
    "\n",
    "#### Spectrum\n",
    "\n",
    "In most Mantid workspaces each spectrum corresponds to data measured at a detector pixel, i.e., at a specific position or region in space.\n",
    "If that is the case, scipp used `spectrum` for this dimension.\n",
    "\n",
    "Note that using the generic `spectrum` should be avoided in other cases.\n",
    "For example, after converting data to `Q` we need to avoid having \"compatible\" dimensions of a data and would use `Q` as a dimension instead.\n",
    "The double meaning of what a \"spectrum\" actually is in Mantid is thus avoided.\n",
    "\n",
    "The spectrum dimension comes with a coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.coords['spectrum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-of-flight\n",
    "\n",
    "In contrast to a `EventWorkspace` in Mantid, a dataset does not necessarily come with a time-of-flight (TOF) coordinate (bin edges) on top of the TOF values for the events.\n",
    "Therefore dimension `tof` does not have a corresponding *dense* coordinate.\n",
    "See below for *sparse* TOF coordinates.\n",
    "\n",
    "### Non-dimension coordinates\n",
    "\n",
    "Scipp stores auxiliary coordinate \"labels\" as non-dimension coordinates.\n",
    "Dimension and non-dimension coordinates (and not attributes) are used to ensure that information is compatible in operations involving multiple data arrays or dataset.\n",
    "\n",
    "This actually happended internally when we first loaded the files for `'sample'` and `'vanadium'` and inserted them into the same dataset:\n",
    "if the files had had different spectrum numbers or spectrum positions the insertion of the `'vanadium'` data would have failed due to incompatible coordinates.\n",
    "\n",
    "#### Position\n",
    "\n",
    "Positions are an auxiliary coordinate for dimension `spectrum`, in other words they could be used to \"label\" the spectrum coordinate, e.g., in an a plot.\n",
    "The main purpose of storing postions as labels instead of, e.g., attributes is to ensure that operations between data with mismatching detector positions fail and thus prevent mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.coords['position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position coordinate stores the positions of all spectra.\n",
    "Each position is a 3-component vector (X, Y, Z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beamline geometry\n",
    "\n",
    "Apart from positions of spectra we require additional geometry information for various components in a neutron beamline (instrument).\n",
    "This is stored as labels such as `'source_position'` and `'sample_position'`.\n",
    "We instead recommend the use of helper functions such as `sample_position` which will be discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.coords['sample_position'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We emphazise the importance of storing this information as coordinates.\n",
    "This ensures that we cannot accidentally combine data obtained with, e.g., different sample positions.\n",
    "\n",
    "*Bonus note:\n",
    "If we ever* **do** *want to combine data with different samples we can either remove this information from the dataset, or change it to an* **attribute**.\n",
    "\n",
    "For convenient and standardized access, as well as access of derived information such as scattering angles, a number of helper functions is provided.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.neutron.sample_position(events).copy() # copy is a temporary hack since const view lacks some properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.neutron.scattering_angle(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of available beamline-geometry helpers please refer to the [documentation](https://scipp.github.io/additional-modules/scipp-neutron.html#beamline-geometry)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus note:\n",
    " For the most part, the structure of `ComponentInfo` (and `DetectorInfo`) in Mantid is easily represented by a `Dataset`, i.e., very little change is required.\n",
    " For example, scanning is simply handled by an extra dimension of, e.g., the position and rotation variables.\n",
    " By using `Dataset` to handle this, we can use exactly the same tools and do not need to implement or learn a new API.*\n",
    " \n",
    "### Attributes\n",
    "\n",
    "Attributes allow for storing information with data in a way that leaves it untouched in normal operations.\n",
    "This is used for storing meta-data that does not require processing alongside normal data.\n",
    "For neutron data key examples are: run information, sample information, and neutron monitors.\n",
    "Scipp simply stores Mantid's `Run` and `Sample` objects in the `\"run\"` and `\"sample\"` attributes.\n",
    "Monitors are stored, per dataset item (`sample`, `vanadium`), in an attribute named `\"monitorN\"`, where `N` is the monitor number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.to_html(events['sample'].attrs['run'])\n",
    "sc.to_html(events['sample'].attrs['sample'])\n",
    "sc.to_html(events['sample'].attrs['monitor1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are attributes of the sample (or vanadium).\n",
    "A dataset itself can also have attributes, but in this case it does not.\n",
    "Each of the attributes above is a 0-D variable, the easiest way to access this value is the `value` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mantid_run = events['sample'].attrs['run'].value\n",
    "print('The run contains the following properties:\\n{}\\n'.format(mantid_run.keys()))\n",
    "\n",
    "mantid_sample = events['sample'].attrs['sample'].value\n",
    "print('Sample name: {}\\n'.format(mantid_sample.getName()))\n",
    "\n",
    "# Each monitor (just 1 in this case) is stored as a data array\n",
    "print('Monitor:')\n",
    "sc.to_html(events['sample'].attrs['monitor1'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event data\n",
    "\n",
    "Neutron events are stored as **sparse data** in contrast to the regular gridded (\"dense\") data of, e.g., histogrammed data.\n",
    "See [the scipp documentation](https://scipp.github.io/user-guide/sparse-data.html) for more information.\n",
    "\n",
    "The number of neutrons detected at each position is different and thus scipp has no fixed definition for the length of the \"sparse\" dimension.\n",
    "This looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show(events['spectrum', 10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data structure is to be interpreted as follows:\n",
    "\n",
    "- Each position sees a different number of events, and events arrive at random time.\n",
    "  Therefore, there is a time-of-flight for *every pixel*, for *every event*, and for *every data item* (`'vanadium'` and `'sample'`).\n",
    "  This **sparse coordinate** has the following properties:\n",
    "  - The sparse coord for `tof` is associated with a data item and is not global for the dataset.\n",
    "  - The sparse coord for `tof` depends on dimension `spectrum`.\n",
    "  - The sparse coord for `tof` has a different length for each spectrum.\n",
    "- Extra information such as pulse times are stored as sparse labels.\n",
    "  What was said above for sparse coords also applies to sparse labels.\n",
    "  The length at each position matches the corresponding length of the sparse coordinate.\n",
    "- Values and variances are optional.\n",
    "  They would represent weight and weight uncertainties of events.\n",
    "  If they are not present an implicit weight of `1` is assumed, i.e., each coord value corresponds to a single neutron.\n",
    "\n",
    "The time-of-flight values for an individual pixel could be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['sample'].coords['tof']['spectrum', 10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From events to histogram\n",
    "\n",
    "We histogram the event data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sc.Variable(['tof'], values=np.arange(1000.0, 20000.0, 50.0), unit=sc.units.us)\n",
    "d = sc.histogram(events, bins)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(d['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake instrument view\n",
    "\n",
    "Just for fun, we can quickly generate a crude \"instrument view\".\n",
    "In this case this works since we have only a single panel.\n",
    "If there were multiple panels, they could be handled as an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = sc.Dataset()\n",
    "# 154 and 7 are the extents of the panel\n",
    "panel['sample'] = sc.reshape(d['sample'].data, ['x', 'y', 'tof'], (154,7,379))\n",
    "panel.coords['tof'] = d.coords['tof']\n",
    "# Note that the scale is meaningless, could use real instrument parameters\n",
    "panel.coords['x'] = sc.Variable(['x'], values=np.arange(154))\n",
    "panel.coords['y'] = sc.Variable(['y'], values=np.arange(7))\n",
    "# Move TOF slider around 12000 to see diffraction lines moving across the panel\n",
    "plot(panel['tof', 180:260], axes=['tof', 'y', 'x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitors\n",
    "\n",
    "If loaded, monitors are available as an attribute named `\"monitorN\"`.\n",
    "For demonstration purposes we can add some fake monitors to demonstrate the versatility of `Dataset`.\n",
    "Storing each monitor as a separate variable that contains a nested data array gives us complete freedom and flexibility.\n",
    "Another approach would be to use a single 1-D variable containing monitor data arrays as elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram-mode beam monitor\n",
    "edges = np.arange(0.0, 20000.0, 1000.0)\n",
    "counts = np.random.rand(len(edges)-1)\n",
    "beam = sc.DataArray(\n",
    "    data=sc.Variable(['tof'], values=counts, variances=counts, unit=sc.units.counts),\n",
    "    coords={'tof': sc.Variable(['tof'], values=edges)})\n",
    "\n",
    "# Event-mode transmission monitor\n",
    "events = sc.Variable(['tof'], shape=[sc.Dimensions.Sparse])\n",
    "events.values = np.random.rand(123456)\n",
    "transmission = sc.DataArray(coords={'tof': events})\n",
    "\n",
    "# Beam profile monitor\n",
    "profile = sc.DataArray(\n",
    "    data=sc.Variable(['y', 'x'], values=np.random.rand(20, 20), unit=sc.units.counts),\n",
    "    coords={\n",
    "        'x': sc.Variable(['x'], values=np.arange(-0.1, 0.11, 0.01)),\n",
    "        'y': sc.Variable(['y'], values=np.arange(-0.1, 0.11, 0.01))\n",
    "    })\n",
    "for i in 1,2,3,4:\n",
    "    profile['x', i:-i]['y', i:-i] += 1.0 * sc.units.counts\n",
    "\n",
    "plot(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.Variable(value=transmission)\n",
    "d['sample'].attrs['transmission'] = sc.Variable(value=transmission)\n",
    "d['sample'].attrs['beam'] = sc.Variable(value=beam)\n",
    "d['sample'].attrs['profile'] = sc.Variable(value=profile)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Normalize the sample data to the monitor in the `\"monitor1\"` attribute.\n",
    "This involves a couple of steps:\n",
    "1. Normalization in time-of-flight does not make sense. Convert to, e.g., wavelength.\n",
    "2. The data and the monitor have mismatching bins. Rebin to common binning.\n",
    "3. Normalize. \n",
    "\n",
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sc.neutron.convert(d['sample'], 'tof', 'wavelength')\n",
    "# Using bins of first spectrum here, other choices are just as valid\n",
    "sample = sc.rebin(sample, 'wavelength', sample.coords['wavelength']['spectrum', 0])\n",
    "\n",
    "mon = d['sample'].attrs['monitor1'].value\n",
    "mon = sc.neutron.convert(mon, 'tof', 'wavelength')\n",
    "mon = sc.rebin(mon, 'wavelength', sample.coords['wavelength'])\n",
    "\n",
    "plot(mon)                             \n",
    "sample_over_beam = sample / mon\n",
    "plot(sample_over_beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now continue with the normalized data, but in the following we do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = d['sample']\n",
    "temp_scan = sc.concatenate(sample, sample * (0.8 * sc.units.dimensionless), 'temperature')\n",
    "temp_scan = sc.concatenate(temp_scan, temp_scan * (0.64 * sc.units.dimensionless), 'temperature')\n",
    "temp_scan.coords['temperature'] = sc.Variable(['temperature'], values=[4.3, 100.0, 180.0, 273.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(temp_scan['spectrum', 20:], axes=['temperature', 'spectrum', 'tof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(temp_scan['spectrum', 500], collapse='tof')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit conversion\n",
    "\n",
    "Unit conversion is available in the `scipp.neutron` submodule.\n",
    "Converting a data array or dataset to a different unit implies changing one of the dimensions and its coordinate.\n",
    "Conversion can also be done with sparse data (events), but we are using the histogrammed data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.neutron.convert(d, 'tof', 'd-spacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cannot handle ragged coordinates at this point, rebin to edges of first spectrum\n",
    "d = sc.rebin(d, 'd-spacing', d.coords['d-spacing']['spectrum', 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = sc.sum(d, 'spectrum')\n",
    "plot(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalized = summed['sample'] / summed['vanadium']\n",
    "plot(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (advanced)\n",
    "\n",
    "Instead of loading only a single bank, load multiple, e.g., `bank124`, `bank144`, `bank164`, and `bank184`.\n",
    "Modify everything in this notebook to work with the new multi-bank data, obtaining a separate focussed diffraction spectrum for each bank.\n",
    "\n",
    "There is more than one option to solve this:\n",
    "1. Concatenate the loaded data into a single dataset, resulting in more or larger dimensions.\n",
    "2. Merge the loaded data into a single dataset, resulting in differently named variables for each bank.\n",
    "3. Call the existing code as-is for each bank, working, e.g., for a Python `list` of datasets.\n",
    "\n",
    "Each of the approaches has its advantages and drawbacks.\n",
    "\n",
    "Here we recommend option 1, which in itself can be implemented in one of two ways:\n",
    "- Concatenate along a new `bank` dimension.\n",
    "- Concatenate along the existing dimension `spectrum`.\n",
    "\n",
    "*Note: You will likely experience some small problems with plotting, in particular issues with multi-dimensional coordinates in the first case (we suggest to slice manually until this is supported), and large gaps in the second case (can be avoided by adding a helper-coordinate).*\n",
    "\n",
    "*Bonus note for option 3: Unlike Mantid workspaces, datasets can safely be used in combination with Python containers. Do not try this with workspaces, since they are entangled with the `AnalysisDataService`.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
